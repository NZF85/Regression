---
title: "Project regression"
output: word_document
---

Transformation of variables to factors

mtcars dataframe contains 11 categories of numerical variables. The first step is to transform all categorical variables to factors.

```{r}
data(mtcars)
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs, labels=c('V-Engine','Straight'))
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
mtcars$am <- factor(mtcars$am,labels=c('Automatic','Manual'))
```

Exploratory analysis


```{r, echo=FALSE,fig.height=8, fig.width=6}
options(warn=-1)
library(car)
scatterplotMatrix(~mpg + cyl + disp + hp + drat + wt + qsec + vs + am + gear + 
    carb, data = mtcars, main = "Plot 1: Scatterplot Matrix")
```
From the scatterplot, variables like cyl, disp, hp, drat, wt, vs and am seem to have some strong correlation with mpg. We will use linear models to quantify that in the next section.


```{r, echo=FALSE,fig.height=8, fig.width=6}
boxplot(mpg ~ am, data = mtcars, main = "Plot 2: Miles per gallon by Transmission type", 
    xlab = "Transmission type", ylab = "Miles Per Gallon")
```
The boxplot of the variable mpg when am is 'Automatic' or 'Manual' shows that the mpg incresases when the transmission is 'Manual'.


Regression model

```{r}
fullModel <- lm(mpg ~ ., data=mtcars)
summary(fullModel)
```

This model has the Residual standard error as 2.833 on 15 degrees of freedom. And the Adjusted R-squared value is 0.779, which means that the model can explain about 78% of the variance of the MPG variable. However, none of the coefficients are significant at 0.05 significant level.

Then, we use backward selection to select some statistically significant variables.

```{r}
stepModel <- step(fullModel, k=log(nrow(mtcars)))
summary(stepModel) # results hidden
```
This model is "mpg ~ wt + qsec + am". It has the Residual standard error as 2.459 on 28 degrees of freedom. And the Adjusted R-squared value is 0.8336, which means that the model can explain about 83% of the variance of the MPG variable. All of the coefficients are significant at 0.05 significant level.

```{r}
anova(fullModel,stepModel)
```


```{r}
par(mfrow=c(2, 2))
plot(stepModel)
```
Everything seems fine, Residuals vs Fitted and Scale-Location plots show no pattern, the Normal Q-Q plot indicates that Residuals approximately follow a Normal distributions, and the Residuals vs Leverage plot tell us that there's none particular outlier to be concerned. (There's just one to the right of the plot, but it isn't further than the 0.5 Cook's distance)
